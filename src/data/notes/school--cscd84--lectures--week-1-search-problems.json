{
  "id": "school--cscd84--lectures--week-1-search-problems",
  "path": "school/cscd84/lectures/week-1-search-problems",
  "title": "Week 1 - Search Problems",
  "content": "# Week Notes\n\n[Link](https://www.cs.utoronto.ca/~strider/docs/D84_Search.pdf)\n### Intelligent Agent\n\nAn entity that:\n- **Senses the Environment** using data it either obtains, perhaps with sensors, or is provided. \n- **Takes action in order to achieve a predefined goal.** \n\t- Action means that the agent is able to affect the state of the environment\n- **The Goal:** Defines what the agent is intended to achieve, and is usually encoded in the form of a function that the agent must either minimize or maximize. \n\nA smart thermostat and Tesla's autopilot are both examples of agents.\n\n**Reactive Agents** act solely on environment conditions. The smart thermostat is an example of a reactive agent.\n## Search Problems\n\n**Method:** Given a problem, and a concrete definition of how a solution to this problem is specified, try out every possible solution until we find the best (or the correct) one.\n#### Components of Search Problems\n\n1. A definition of what a configuration or state for the problem we are solving looks like\n\t1. We must know what variables define our environment. \n\t\t1. These variables are then called **state variables**. \n\t\t2. Assignments to these variables are a **state** or **configuration** for this problem\n2. A definition of how actions taken by taken either our or other agents affect the problem state\n\t1. Given the current configuration we can then determine the future configurations\n\t2. This can be deterministic or stochastic. \n\t\t1. **Deterministic**: a transition function `T(s,a)` returning the next state of `s` given `a`\n\t\t2. **Stochastic**: a transition function `T(s,a,s_prime)` returning probability that the next state of `s` given agent action `a` will be `s_prime`\n3. A definition of a goal state(s)\n\nSearch problems are naturally represented by *graphs*. The nodes represent possible configurations. \n\nWe can of course use BFS and DFS to solve this.\n### Uniform Common Search - Searching on Weighted Graphs\n\nLike Dijkstra's: **Guaranteed to find the optimal path to a goal node** if such a path exists under the condition that all edge weights are greater than zero.\n\n- Use a priority queue to keep nodes to visit \n- When expanding a node `v` that is not goal, for each neighbour `u` add it to priority queue with the cost to get to `u` from the start node. If `u` is already in the priority queue see if the path through `v` is cheaper and update if it is.\n### Heuristic or A* (A-star) Search\n\nUses a heuristic function to guess which noes in the search tree are likely to be closer to a goal state in combination with the actual cost of getting to a node from the initial state. \n\nThe **heuristic cost** used by **A**** search is `f(n) = g(n) + h(n)`\n\nWhere `f(n)` is the heuristic cost for some node `n`, and it consists of `g(n)` – the actual cost of reaching node `n` from the initial node, and `h(n)` a guess of the cost to get to [the/a] goal state from `n`.\n\n*The algorithm is basically just UCS* but priority queue ordering is determined by `f(n)` rather than just `g(n)`\n\n#### What makes a good heuristic?\n\nIn order for a heuristic to preserve the optimality guarantee of UCS, it must be **admissable**.\n\n**Admissible Heuristic**: A heuristic `h(n)` is admissible if and only if:\n\n$\\forall n, 0 \\leq h(n) \\leq h^*(n)$\n\nwhere $h^*(n)$ is the true cost of getting to the goal node from node $n$. **BUT we don't know $h^*(n)$ so this is tough!**\n\n- An admissible heuristic is *optimistic* – it does not over-estimate the cost of getting to the goal\n- If the heuristic is NOT admissible then the A* process can return a sub-optimal path.\n### Bellman-Ford Algorithms \n\n#### What if there are negative weights?\n\nThis can happen if certain paths have rewards for our agent.\n\nCan still get a optimal solution if there are no negative-weight cycles.\n##### Why not get rid of the negative weights by adding a constant?\n\n<img src=\"/images/Weighted_Graph.png\" alt=\"Weighted Graph\" />\n\nTry running Dijkstra's starting at A. It won't find the shortest path to C even if we add 10 to each weight.\n### Pseudocode\n\nDijkstra's fails on negative weight graphs because it's greedy and always chooses the lowest cost. *BF will use a DP approach to iteratively improve on the shortest possible path and will consider all edges in the graph at every iteration.*\n\n```python\ndef bf(nodes, edges):\n\tn, m = len(nodes), len(edges)\n\tdist = [0] * n\n\tdist[0] = 0\n\tfor i in range(1, n):\n\t\tdist[i] = float('inf') # lec notes say 1e10 but any large number works\n\tpred = [-1] * n\n\t\n\tfor _ in range(n - 1):\n\t\tfor (i, j), cost in edges:\n\t\t\tif dist[i] + w < dist[j]:\n\t\t\t\tdist[j] = dist[i] + w\n\t\t\t\tpred[j] = i\n\n```\n\nTC `O(NM)`\n# Lecture Notes\n\n# When Revising\n\n## From Notes\n\nDefine a cost function for a realistic driving directions application which accounts for:\n\n- Real-time traffic information (you must specify how this is encoded in the cost) \n- Real-time updates for accidents and other disruptions that may close-off streets \n- Intersections (cars do not move instantly from one street to the next, some intersections are worse than others) \n\nGiven your cost function, suggest a heuristic that can be used to reduce the amount of search required to find a good rout\n## From Lecture",
  "metadata": {
    "date": "2026-01-16",
    "updated": "2026-01-16"
  },
  "images": [
    "/images/Weighted_Graph.png"
  ],
  "links": []
}