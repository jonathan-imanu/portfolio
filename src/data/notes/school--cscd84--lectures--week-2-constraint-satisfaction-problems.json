{
  "id": "school--cscd84--lectures--week-2-constraint-satisfaction-problems",
  "path": "school/cscd84/lectures/week-2-constraint-satisfaction-problems",
  "title": "Week 2 - Constraint Satisfaction Problems",
  "content": "# Week Notes\n\n**A subset of search problems related to finding some assignment that satisfies a variety of constraints**\n- Such as how the university builds out it's timetable and room assignments or sudoku.\n### Components of a CSP\n\n- A **set of variables** whose values are to be set\n- The **domain** for each of the variables\n\t- Must be *finite and discrete-valued*\n- A set of **constraints** on either individual variables or subsets of variables that help determine which value assignments are **valid** and which are not.\n- Constraints can be **unary** (apply to a single variable) or **higher order** (relating 2+)\n\nCommonly represented as a graph with nodes corresponding to variables and edges corresponding to constraints.\n- There are multiple ways of framing a problem and this affects the computation of a CSP.\n\t- Consider mapping courses to time slots or time slots to courses\n\nA simple approach is just backtracking. Typically called *backtracking search*\n##### Bookkeeping\n\nWe can speed up the naive approach by doing some *bookkeeping*. Bookkeeping would result in us constraining the set of valid choices for neighbours of `v` based on our choice for `v`.\n\n> Recall the map colouring problem: \"Given a map of Europe, with colours {R,Y,G,B}, colour the map such that no neighbouring countries share the same border.\"\n> \n> So in this case, if we colour Italy with Red then it's neighbours should not have Red as an option. Can do this with sets.\n\n#### Heuristics to Speed Up Backtracking Search\n\nTo be applied in order:\n\n1. Choose the variable with the *fewest remaining values* first\n\t1. Whenever a set is empty, we have to backtrack immediately\n\t2. Speeds up by reduces fruitless work within subtrees and reducing the branching\n2. If there's a tie in **1.**, choose the variable involved in the *largest number of active constraints*. IE the variable that places the most constraints on others\n\t1. Speeds up by reducing branching factor for succeeding levels in the search tree\n\nIf there is a tie by rules **1.** and **2.**, can choose from the tied variables arbitrarily.\n\n3. Given a choice of a variable to expand (IE assign a colour to a country NOT pick a country), choose first the least constraining value\n\nEven with these heuristics, TC is still $O(d^n)$ for a CSP with $n$ variables and a domain $d$\n### Tree Structured CSPs\n\n**A CSP whose constraint graph has no loops is a tree-structured CSP.**\n- Can be solved in $O(Nd^2)$\n\n1. Choose a root variable and perform topological sort so the children of each node appear after their parent. Initialize the set of valid values for each variable in the CSP.\n2. Backward (first) pass\n\t1. Check the parent of each node and remove any values that would make the constraints in the problem not valid\n3. Backtracking search (second, forward pass) \n\t1. The search will not backtrack because any value chosen for a parent is consistent with the constraints on the children.\n\n> What does it mean if at some point while removing possible values from a parent node’s list, that list becomes empty?\n\nNo solution exists. \n### Cutset Conditioning\n\nA way of using the tree structured CSP algorithm on non-tree constraint graphs by *assigning values to a subset of variables so that we can disconnect them from the rest of the CSP*.  Since  we assigned values arbitrarily to some subset of variables and there’s no guarantee that the initial assignments to these variables still allow for a solution to the CSP to be found.\n\nHence we have to try all possible combinations of variables that are included in the subset. Thus TC becomes $O(d^k (N-k)d^2)$\n### Iterative Methods and Approximate Solutions to CSPs\n\nIf solving a CSP is too expensive and we want a fast \"good enough\" solution\n#### Local Search: Simplest and Most General\n\n```\nRandomly generate a full assignment of values to variables in the CSP \n\nits=0 \nwhile its < MAX_ITERATIONS\n\tlet v be a randomly picked varible with conflicts \n\tnew_v := a randomly chosen new value for v\n\t\n\tif is_solution(new_v): \n\t\tSTOP\n\t\n\tif broken_constraints(new_v) < broken_constraints(v):\n\t\tset v = new_v\n\tits ++\n```\n\nCalled local search since *at each step only one variable changes value so each successive guess at a solution is close in solution space to the previous one*. Looking around the *neighbourhood of possible solutions* from where we currently are.\n\nAlso called hill climbing.\n\nWe can get stuck at a local minimum! \n##### Improving Local Search\n\n1. Running it $k$ times and keeping the best result\n2. **Deterministic Annealing**, it is a variation of local search that allows the process to keep a solution even if it is worse than the current one with some probability.\n3. **Beam search/Taboo search**, keep track of multiple guesses found in the search process and attempt to maximize the chance of finding a good solution.\n4. **Genetic algorithms**\n# Lecture Notes\n\n# When Revising\n",
  "metadata": {
    "date": "2026-01-16",
    "updated": "2026-01-16"
  },
  "images": [],
  "links": []
}